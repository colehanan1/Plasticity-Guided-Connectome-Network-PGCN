"""Serve the multi-task Drosophila model behind a FastAPI interface."""
from __future__ import annotations

import argparse
from pathlib import Path
from typing import List, Optional

import torch

try:  # pragma: no cover - optional API dependency
    from fastapi import FastAPI, HTTPException
    from pydantic import BaseModel
    import uvicorn
except ImportError as exc:  # pragma: no cover - fail fast when dependencies missing
    raise ImportError(
        "FastAPI deployment requires 'fastapi' and 'uvicorn'. Install them with 'pip install pgcn[api]'."
    ) from exc

from pgcn.data import load_multi_task_config
from pgcn.models import MultiTaskDrosophilaModel, TaskHeadConfig


class PredictionRequest(BaseModel):
    task: str
    pn_activity: List[List[float]] | List[float]
    apply_activation: bool = True
    return_kc: bool = False


class PredictionResponse(BaseModel):
    task: str
    predictions: List[List[float]]
    mbon_activity: Optional[List[List[float]]] = None
    kc_activity: Optional[List[List[float]]] = None


def _normalise_activity(payload: List[List[float]] | List[float]) -> torch.Tensor:
    tensor = torch.as_tensor(payload, dtype=torch.float32)
    if tensor.dim() == 1:
        tensor = tensor.unsqueeze(0)
    if tensor.dim() != 2:
        raise ValueError("PN activity must be a list or list of lists.")
    return tensor


def build_model(config_path: Path, checkpoint: Optional[Path], tasks: Optional[List[str]]) -> MultiTaskDrosophilaModel:
    config = load_multi_task_config(config_path)
    head_configs: dict[str, TaskHeadConfig] = {}
    for name, spec in config.tasks.items():
        if tasks and name not in tasks:
            continue
        head_configs[name] = TaskHeadConfig(
            output_dim=spec.output_dim,
            activation=spec.activation,
            loss=spec.loss_function,
            dropout=spec.dropout,
            use_reservoir_head=spec.use_reservoir_head,
        )
    if not head_configs:
        raise ValueError("No task heads available for deployment; check the --tasks argument.")
    model = MultiTaskDrosophilaModel(cache_dir=config.reservoir.cache_dir, task_configs=head_configs)
    model.freeze_reservoir()
    if checkpoint:
        state = torch.load(checkpoint, map_location="cpu")
        missing, unexpected = model.load_state_dict(state, strict=False)
        if missing:
            print(f"[WARN] Missing parameters during checkpoint load: {missing}")
        if unexpected:
            print(f"[WARN] Unexpected parameters during checkpoint load: {unexpected}")
    model.eval()
    return model


def create_app(model: MultiTaskDrosophilaModel) -> FastAPI:
    app = FastAPI(title="PGCN Multi-task Deployment", version="1.0")

    @app.get("/tasks", response_model=List[str])
    def list_tasks() -> List[str]:
        return list(model.available_tasks())

    @app.post("/predict", response_model=PredictionResponse)
    def predict(request: PredictionRequest) -> PredictionResponse:
        if request.task not in model.available_tasks():
            raise HTTPException(status_code=404, detail=f"Task '{request.task}' not registered")
        pn_activity = _normalise_activity(request.pn_activity)
        if pn_activity.size(-1) != model.reservoir.n_pn:
            raise HTTPException(
                status_code=400,
                detail=f"PN activity dimensionality {pn_activity.size(-1)} does not match reservoir ({model.reservoir.n_pn}).",
            )
        with torch.no_grad():
            outputs = model.forward(pn_activity, tasks=[request.task], return_kc=request.return_kc)
            if request.apply_activation:
                predictions = model.predict_task(request.task, pn_activity)
            else:
                predictions = outputs[request.task]
        response = PredictionResponse(
            task=request.task,
            predictions=predictions.cpu().numpy().tolist(),
            mbon_activity=outputs["mbon_activity"].cpu().numpy().tolist(),
        )
        if request.return_kc and "kc_activity" in outputs:
            response.kc_activity = outputs["kc_activity"].cpu().numpy().tolist()
        return response

    return app


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--config", default="configs/multi_task_config.yaml", help="Multi-task YAML configuration")
    parser.add_argument("--checkpoint", help="Optional checkpoint generated by train_multi_task.py")
    parser.add_argument("--tasks", nargs="*", help="Optional subset of tasks to expose")
    parser.add_argument("--host", default="0.0.0.0")
    parser.add_argument("--port", type=int, default=8000)
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    config_path = Path(args.config)
    checkpoint_path = Path(args.checkpoint) if args.checkpoint else None
    model = build_model(config_path, checkpoint_path, args.tasks)
    app = create_app(model)
    uvicorn.run(app, host=args.host, port=args.port)


if __name__ == "__main__":  # pragma: no cover - CLI entry point
    main()
